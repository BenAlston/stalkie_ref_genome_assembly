
# **Reference Genome Assembly**

[Useful resource](https://github.com/alexjvr1/T.dalmanni_Genomics_of_meiotic_drive/blob/main/Electronic_Lab_Book.md#1-genome-assembly)

Current _T. dalmanni_ ref is ~0.383 Gb and 3 chromosomes

## **Genome Size Estimation with Jellyfish**
* version V 2.2.10
* [documentaiton](https://github.com/gmarcais/Jellyfish)
* Ran [jellyfish.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/blob/main/scripts/jellyfish.sh) on each species
* Used [genomescope](http://qb.cshl.edu/genomescope/) to visualise the .histo files generated by jellyfish (read length=10000, max kmer coverage=100000)
* [genomescope plots](https://github.com/BenAlston/stalkie_ref_genome_assembly/tree/main/lab_book/Data/jellyfish_histos%20)


# **Assembly with Hifiasm**
* [Documentation](https://github.com/chhylp123/hifiasm)
* Ran [hifiasm.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/blob/main/scripts/hifiasm.sh) (Hifiasm V 0.16.1), takes ~10-12 hrs

### Samples:

  ~~~
  - 7 total, 2 per species (1M, 1F), plus 1 additional T. whitei F (potential driver).
  - Assemblies should be generated for each sample, so 7 assemblies total.
  - Two HiFi .fastq.gz files per individual (so 4,4,6) per species.
  ~~~

| Sample ID | file\_prefix | Species         | Sex    |
| --------- | ------------ | --------------- | ------ |
| ST1       | 200437\_1    | C.whitei        | Female |
| ST2       | 200437\_2    | C.whitei        | Male   |
| ST3       | 200437\_3    | C.whitei Driver | Female |
| ST6       | 200437\_4    | D.meigenii      | Female |
| ST7       | 200437\_5    | D.meigenii      | Male   |
| ST8       | 200437\_6    | T.dalmanni      | Male   |
| ST9       | 200437\_7    | T.dalmanni      | Female |

### **Initial Hifiasm Assemblies**
* [output files documentation](https://hifiasm.readthedocs.io/en/latest/interpreting-output.html)
* duplication looks very high across the board, not very contiguous, also a lot larger than expected


|sample| info         | est_size         | primary_assembly_size | busco_completeness | busco_dup | contigs | N50 (Kb) |
|-----|-----------------|------------------|-----------------------|--------------------|-----------|---------|-----|
| whitei_1 | female       |        597436869 | 761502157             | 95.8               | 35.6      | 7589    | 156 |
| whitei_2 | male       | 424970908        | 730392625             | 95.1               | 25.6      | 6466    | 178 |
| whitei_3 | female,potential driver |        584931232 | 731617842             | 95.7               | 42.3      | 6774    | 178 |
| meigenii_4 | female      |        694112101 | 694692253             | 96.4               | 28.6      | 3136    | 463 |
| meigenii_5 | male     | 477607885        | 742331081             | 96.3               | 16.9      | 3064    | 576 |
|dalmanni_6 | male       | 657136228        | 700361654             | 97.8               | 25.7      | 2913    | 687 |
| dalmanni_7 | female       |        533280821 | 609130602             | 97.3               | 4.9       | 2425    | 998 |




### **BUSCO**
* Used a docker/apptainer image
* ran [busco.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/blob/main/scripts/busco.sh), takes ~10-20 mins
* see [busco output](https://github.com/BenAlston/stalkie_ref_genome_assembly/tree/main/lab_book/Data/BUSCO_output)
* very high duplication across all species, completeness is ok

### **Checking Coverage is as Expected**
* genomescope plots are no longer working, will need redoing
* Hifiasm outputs have been misplaced, rerruning for meigenii and make sure it's all working, saving the outputs somewhere sensible this time
* meigenii_4: peak_hom: 29; peak_het: 16, matches my jellyfish output, i'll check the other ones to make sure as well

* 
# Cleaning Assemblies
* The current plan is to remove contamination using blobtoolkit, then remove duplicated haplotypes using purge_dups

## **Filtering Contamination with Blobtoolkit**
* [documentation](https://github.com/blobtoolkit/blobtoolkit)
* essentially takes blast output, coverage, and busco output, and filters the dataset for contamination
* Needs:
  - blast.out file (generated in [blast_par.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/tree/main/scripts/blast_par.sh))
  - coverage (generated in [blobtoolkit.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/edit/main/scripts/blobtoolkit.sh))
  - busco (generated in [busco.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/tree/main/scripts/busco.sh))
### **Blast**

**Installing local blast database**
* Remote searches take too long, so installed the local Blast nt db ([using blast_nt_db.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/blob/main/scripts/blast_nt_db.sh)), this takes up ~500GB of space
* Blasting my highly contiguous assemblies will take too long unless it is parallelised

**Parallelising Blast**
* split my assembly fasta into 500 smaller files: ran [fasta_splitter.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/blob/main/scripts/fasta_splitter.sh)
* ran blast on each using an array script, [blast_par.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/tree/main/scripts/blast_par.sh)
* Then I condensed these blast output files into a single file:
~~~
cat out/* >> all_blast.out
~~~

## **Blobtoolkit pipeline:**
* Ran [blobtoolkit.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/edit/main/scripts/blobtoolkit.sh)
* This script takes the blast output I just generated, busco output from [busco.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/edit/main/scripts/busco.sh), calculates coverage. It then filters the assembly for contamination, I am able to specify which taxanomic rank blast matches I want removed.
* **<Important>** generating coverage using minimap2 does not work for dalmanni_6, this is likely an issue to to with the HiFi reads being to long.
* This analysis has currently been run on whitei_1 and whitei_2 only.

#### **Setting Filter Parameters**
* Need to select appropriate taxanomic level to filter
* The below table was generated with: --param bestsum_$clade_rank--keys=no-hit,$clade # this keeps only reads with blast hits from that clade, and reads with no blast hits

| Clade      | Size (Gb) | Contigs | Completeness | Duplication|
|------------|-----------|---------|--------------|------------|
| Unfiltered | 0.762     | 7598    | 95.8         | 35.6       |
| Eukaryota  | 0.748     |  7481   | 95.7         | 35.6       |
| Metazoa    | 0.
| Arthropoda | 0.742     | 7363    | 95.6         | 35.5       |
| Diptera    | 0.715     | 6933    | 95.3         | 35.3       | 
* Metazoan and no blast matches seem to be the most sensible contigs to retain.


**Summary:**
* Can't add coverage for Dalmanni_6
* ran [blobtoolkit.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/new/main/scripts/blobtoolkit.sh), filtered the assembly to retain only metazoan and no blast match reads

## **Purge Dups**
* [Documentation](https://github.com/dfguan/purge_dups)
* First running this pipeline on whitei F (sample 1) since its busco dup is 35%
*
* Ran through generating a config directory (using [purge_dups_config.sh](https://github.com/BenAlston/stalkie_ref_genome_assembly/tree/main/scripts/purge_dups_config.sh)), the output purged assembly has very clearly gone horribly wrong (40% completeness). It would be nice if the output was explained in the documentation.
* Ran the manual pipeline instead, so I can manually control parameters.

**Manual pipeline**
* Issues generating .paf files
* running paf_gen.sh - works
* ran the pipeline, on whitei_1

whitei_1 pre and post purge_dups_manual.sh
|              | length (gb) | contigs | dup (%)| Conpleteness (%) | n50 (kb) |
| -------------|-------------|---------|--------|------------------|----------|
| pre-purging  | 0.762 | 7589   |  35.6|   95.8         | 156 |
| purge_dups round 1  | 0.475    | 4653      | 3.3    | 90.9     | 161 |
| purge_dups round 2  | 0.542    | 5156      | 1.2    | 95.4     | 177 |

in purge_dups_man_1 & 2.sh, the line: 'minimap2 -xasm5 -DP ${REF}.split ${REF}.split | gzip -c - > $(basename $REF).split.self.paf.gz', check -xasm5 is correct here
* need to make sure purge_dups is doing everything correctly
* set up the script to run on all sampes
* running job  2488718
## **Next Steps:**
*  [findZX](https://github.com/hsigeman/findZX) has potential, look through the paper


4. extract mt genomes
7. use samtools to determine proportion of reads that map
8. map short-read data
9. use samtools to look at coverage




